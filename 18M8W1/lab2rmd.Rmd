---
title: "Eric Breton<br> MSDS - 660 Statistical Methods and<br> Experimental Design<br>"
output:
  html_notebook: default
  pdf_document: default
---

---




```{r}
#First we will get the Data from the Mass Project
library(MASS)
# install.packages('tidyverse')
library(tidyverse)
data(Boston)
View(Boston)
?Boston
```
```{r}
# 1.

#The first thing I had to do for this assignment was to grab the data set from the MASS library. I grabbed the Boston Housing data because it was recommended by the assignment. I then grabbed a list of the headers to find out what information using the ls function. Next I was able to get information about the data set from using the? function. This data set has 506 observations with 14 variables. 

# The 14 variables are:
# Crim =capita crime rate by town.
# Zn =proportion of residential land zoned for lots over 25,000 sq.ft.
# Indus=proportion of non-retail business acres per town.
# Chas=Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
# Nox=nitrogen oxides concentration (parts per 10 million).
# Rm=average number of rooms per dwelling.
# Age=proportion of owner-occupied units built prior to 1940.
# Dis=weighted mean of distances to five Boston employment centres.
# Rad=index of accessibility to radial highways.
# Tax=full-value property-tax rate per \$10,000.
# Ptratio=pupil-teacher ratio by town.
# Black=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.
# Lstat=lower status of the population (percent).
# Medv=median value of owner-occupied homes in \$1000s.

```


```{r}
# 2.
 #In the data that I selected to explore none of their distributions could be defined as not normal and are for the most part pretty irregular.Crime rate in particular has a wide range of numbers so if exloring I may want to trim some outliers to eliminate any impact it could have on my analysis.
summary(Boston$crim)
summary(Boston$chas)
summary(Boston$indus)
summary(Boston$nox)

hist(Boston$crim,main="Crime Rates")
hist(Boston$chas,main="By the River")
hist(Boston$indus,main="Industrial")
hist(Boston$nox, main="Nox Rate")

```

```{r}

#3.
 #Many of the variables which I selected do not have strong or negative correlations with each other. One combo of variables which do show a relatively strong positive correlation is the relationship between nox concentration and industry centers.

plot(Boston$crim,Boston$chas)
plot(Boston$crim,Boston$indus)
plot(Boston$crim,Boston$nox)

plot(Boston$chas,Boston$indus)
plot(Boston$chas,Boston$nox)

plot(Boston$indus,Boston$nox)


```

```{r}
#4
#I will choose nox which is nitrogen oxides concentration (parts per 10 million) for my dependent variable and use the indus which is the proportion of non-retail business acres per town for my independent variable. My objective with these two metrics is to show that industry centric areas of the town produce high levels of nox.
scatter.smooth(x=Boston$indus, y=Boston$nox, main="Indus ~ Nox")  # scatterplot
boxplot(Boston$indus)
boxplot(Boston$nox)
hist(Boston$nox)
hist(Boston$indus)
```


```{r}
#5
  #HO: There is no relation between Indus and NOX concentration
  #H1: There is a relationship between Indus and NOX concentration
```

```{r}
#6
lm_pollution=lm(formula = Boston$nox ~ Boston$indus, data = Boston)
plot(lm_pollution)
summary(lm_pollution)

```

```{r}
#7When running the linear regression model, the first thing I check is whether or not we are rejecting the null hypothesis. In this case we said the null hypothesis was equal to no relationship between the two variables. Nowhere in the model does it simply reject the null hypothesis, we must look at our p - value which we call the probability. The probability indicates that it is unlikely that we observed a relationship between x and y out of chance so there must in fact be some sort of relationship between the two. 

```

```{r}

#8 When looking for evidence of a linear relationship between the predictor and response variable we bring our eyes to R squared which provides us with an alternate  measure of fit. This also measures the proportion of variability in Y that can be explained via X. A R squared close to 1 indicates a very strong linear relationship between X and Y. In this case we had a R squared value of .5823 which indicates a linear relationship between X and Y.
```

```{r}
#9 In using a linear regression model there are certain assumptions we make with the model. One of those assumptions is linearity which states the relationship between the independent and dependent variable to be linear, we can verify that this assumption does not hold based on the scatter plots which were produced in earlier steps. Another assumption is that all of the variables are normal, if you look at the histograms, my variables are not normal. I probably should have thought about that before moving on with my analysis without trying to normalize with a log transformation. (that ship sailed..) The variance assumptions assumes that there is not too much correlation between the dependent and independent variables. When looking at the data in the various plots this assumptions holds true.
```

```{r}
#10 One of the concerns I have is that I need to look closer at my exploration and the assumptions that are required by the linear regression. This may lead to me choosing other variables or making alterations to the variables which were lost.
```



